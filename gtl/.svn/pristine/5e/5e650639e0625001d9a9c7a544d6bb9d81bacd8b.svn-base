package com.admin.pc;

import java.io.BufferedInputStream;
import java.io.DataOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.Reader;
import java.net.HttpURLConnection;
import java.net.URL;
import java.net.URLConnection;
import java.net.URLEncoder;
import java.util.ArrayList;
import java.util.List;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import com.admin.controller.NewsController;
import com.admin.model.News;

public class Test {
	/**
	 * 获取链接
	 * 
	 * @param path
	 * @param re1
	 * @param re3
	 * @return
	 * @throws Exception
	 */
	public List<LinkTypeData> getDatasByCssQuery(String path, String re)
			throws Exception {
		Rule rule = new Rule(path, new String[] { "word" },
				new String[] { "" }, null, -1, Rule.GET);// 第一层扒取
		List<LinkTypeData> extracts = ExtractService.extract(rule);// 获取网页所有的链接
		// //System.out.println(extracts.size());
		List<LinkTypeData> list = new ArrayList<LinkTypeData>();
		for (int i = 0; i < extracts.size(); i++) {
			String text = extracts.get(i).getLinkText();
			String href = extracts.get(i).getLinkHref();
			// //System.out.println(href);
			if (text.matches(re) && href.indexOf("http://") >= 0) {
				list.add(extracts.get(i));
			}
		}
		return list;
	}

	/**
	 * 扒取网页的内容
	 * 
	 * @param path
	 * @param reg
	 * @return
	 * @throws IOException
	 */
	public String getStringByReg(String path, String reg, String zfbmj)
			throws IOException {
		URL url = new URL(path);
		Reader reader = new InputStreamReader(new BufferedInputStream(
				url.openStream()), zfbmj);
		int c;
		StringBuffer sb = new StringBuffer();
		while ((c = reader.read()) != -1) {
			sb.append((char) c);
		}
		reader.close();

		Pattern p = Pattern.compile(reg);
		Matcher m = p.matcher(sb);
		List result = new ArrayList();
		while (m.find()) {
			result.add(m.group());
		}
		StringBuffer sb1 = new StringBuffer();
		for (int i = 0; i < result.size(); i++) {
			sb1.append(result.get(i).toString());
		}
		return sb1.toString();
	}

	public static void main(String[] args) throws Exception {
		Test t = new Test();
		String path = "http://news.baidu.com/";
		String re1 = ".*习近平.*";// 关键字正则表达式习近平.*?
		String re2 = "<p.*?</p>";// 内容正则表达式
		String re3 = "[0-9]{1,}";// 分页正则表达式

		// 1
		List<LinkTypeData> list = t.getDatasByCssQuery(path, re1);
		// 2
		List<LinkTypeData> list_1 = new ArrayList<LinkTypeData>();

		// 扒取第一层链接
		for (int i = 0; i < list.size(); i++) {
			StringBuffer sb = new StringBuffer();
			// 父级url
			String url = list.get(i).getLinkHref();
			// 父级文章
			String content_1 = t.getStringByReg(url, re2, "utf-8");
			sb.append(content_1);

			// 获取子集url
			List<LinkTypeData> l = t.getDatasByCssQuery(url, re3);

			if (l.size() > 0) {
				for (int k = 0; k < l.size(); k++) {
					String con = t.getStringByReg(l.get(i).getLinkHref(), re2,
							"utf-8");
					sb.append(con);
				}
			}

			LinkTypeData lkd = new LinkTypeData();
			lkd.setContent(sb.toString());
			lkd.setLinkHref(url);
			lkd.setLinkText(list.get(i).getLinkText());
			list_1.add(lkd);
		}

		for (int a = 0; a < list_1.size(); a++) {
			String link = list_1.get(a).getLinkHref();
			String text = list_1.get(a).getLinkText();
			String content = list_1.get(a).getContent();
			//System.out.println("链接：" + link);
			//System.out.println("标题:" + text);
			//System.out.println("内容:" + content);
			//System.out.println("***********************************************");
		}
	}
}
